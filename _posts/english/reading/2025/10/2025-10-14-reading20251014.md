---
title: "October 14, 2025 English Reading"
date: 2025-10-14 18:30:00 +0900
categories: [English, Reading]
tags: [english, reading, practice]
---

## **원문**

[https://www.newsinlevels.com/products/deloitte-uses-ai-to-write-a-report-level-3/](https://www.newsinlevels.com/products/deloitte-uses-ai-to-write-a-report-level-3/)

## **해석**

컨설팅 회사인 Deloitte는 호주의 발전과 환경 그리고 노사관계를 위한 정부 보고서를 준비하는 것을 도와주는 AI를 사용한다. 그 보고서는 44만 달러의 비용이 들지만 가짜 법률 인용문과 AI가 만들어낸 참고 문헌들 같은 심각한 문제들이 있다. 이것은 AI가 가끔 사실이 아닌 것을 가져오기 때문에 발생된다. 그것은 차이를 메꾸기 위해 거짓된 정보를 만들어낸다. 그 실수는 교수들에 의해 발견되어 공론화되었다. 비록 Deloitte가 몇몇 디테일들을 수정하고 환불을 해준다고 해도 그 행동은 회사와 정부 모두를 당황하게 하는 원인이 되었다. 전문가들은 이 현상이 전문가의 확인 없이 AI를 사용하는 것에 대한 문제를 보여준다고 말했다. 많은 사업에서 AI를 사용하지만 대부분이 관리 없이 사용중이고 그거은 정밀도에 영향을 미친다. 그 경우에는 기술을 책임지고 있는 조직에 큰 사건이 되기에 그것들을 사실인 것처럼 제시하기 전에 다양한 결과들을 확인해야한다.

## **GPT 교정본**

컨설팅 회사 딜로이트(Deloitte)는 호주 고용 및 직장 관계부의 정부 보고서를 준비하는 과정에서 AI를 활용했다.

그 보고서는 44만 달러의 비용이 들었지만, 가짜 법률 인용문과 AI가 만들어낸 참고문헌 등 심각한 오류들이 포함되어 있었다.

이런 일이 벌어진 이유는 AI가 때때로 “환각(hallucination)”이라 불리는 현상을 일으켜, 사실이 아닌 정보를 빈 부분에 채워 넣기 때문이다.

이 실수들은 한 학자에 의해 발견되어 공개적으로 드러났다.

비록 딜로이트가 일부 내용을 수정하고 부분 환불을 했지만,

이 사건은 회사와 정부 모두에게 큰 망신을 안겼다.

전문가들은 이번 사건이 적절한 인간의 검증 없이 AI를 사용하는 것의 위험성을 보여준다고 지적했다.

많은 기업들이 AI를 사용하지만, 관리자들이 그 사용 범위를 완전히 인식하지 못하는 경우가 많아 ****정확성 문제가 점점 더 커지고 있다.

이번 사례는 조직들이 기술을 책임감 있게 사용하고, 사실처럼 제시하기 전에 결과를 꼼꼼히 검증해야 함을 일깨워주는 경고가 되었다.

## **몰랐던 단어**

- organization: 조직
- accuracy: 정확도
- concern: 영향을 미치다, 우려
- embarrassment: 당황, 망신
- corrected: 수정한
- quote: 인용하다